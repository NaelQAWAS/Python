{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pwd\n",
      "!pip install -U scikit-learn\n",
      "!pip install -U patsy\n",
      "!pip install -U statsmodels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/williamliu\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already up-to-date: scikit-learn in ./anaconda/lib/python2.7/site-packages\r\n",
        "Cleaning up...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already up-to-date: patsy in ./anaconda/lib/python2.7/site-packages\r\n",
        "Cleaning up...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already up-to-date: statsmodels in ./anaconda/lib/python2.7/site-packages\r\n",
        "Cleaning up...\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.formula.api as sm\n",
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv(\"http://data.princeton.edu/wws509/datasets/salary.dat\", sep='\\s+')\n",
      "\n",
      "model = sm.ols(formula=\"sl ~ yr\", data=df).fit()\n",
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>           <td>sl</td>        <th>  R-squared:         </th> <td>   0.491</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.481</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   48.22</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Sun, 09 Mar 2014</td> <th>  Prob (F-statistic):</th> <td>7.34e-09</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>14:25:16</td>     <th>  Log-Likelihood:    </th> <td> -507.38</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>    52</td>      <th>  AIC:               </th> <td>   1019.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>    50</td>      <th>  BIC:               </th> <td>   1023.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th> <td> 1.817e+04</td> <td> 1003.658</td> <td>   18.100</td> <td> 0.000</td> <td> 1.62e+04  2.02e+04</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>yr</th>        <td>  752.7978</td> <td>  108.409</td> <td>    6.944</td> <td> 0.000</td> <td>  535.051   970.544</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td> 5.716</td> <th>  Durbin-Watson:     </th> <td>   1.430</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.057</td> <th>  Jarque-Bera (JB):  </th> <td>   5.015</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 0.509</td> <th>  Prob(JB):          </th> <td>  0.0815</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 4.130</td> <th>  Cond. No.          </th> <td>    15.8</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                     sl   R-squared:                       0.491\n",
        "Model:                            OLS   Adj. R-squared:                  0.481\n",
        "Method:                 Least Squares   F-statistic:                     48.22\n",
        "Date:                Sun, 09 Mar 2014   Prob (F-statistic):           7.34e-09\n",
        "Time:                        14:25:16   Log-Likelihood:                -507.38\n",
        "No. Observations:                  52   AIC:                             1019.\n",
        "Df Residuals:                      50   BIC:                             1023.\n",
        "Df Model:                           1                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept   1.817e+04   1003.658     18.100      0.000      1.62e+04  2.02e+04\n",
        "yr           752.7978    108.409      6.944      0.000       535.051   970.544\n",
        "==============================================================================\n",
        "Omnibus:                        5.716   Durbin-Watson:                   1.430\n",
        "Prob(Omnibus):                  0.057   Jarque-Bera (JB):                5.015\n",
        "Skew:                           0.509   Prob(JB):                       0.0815\n",
        "Kurtosis:                       4.130   Cond. No.                         15.8\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def summary_df(res):\n",
      "    reg_sum = res.summary()\n",
      "    a = reg_sum.tables[1]\n",
      "    af = [[b.strip() for b in row.split(',')] for row in ('feature'+a.as_csv()).split('\\n')]\n",
      "    \n",
      "    for wq in af:\n",
      "        if size(wq)>6:\n",
      "            print wq\n",
      "    rf = pd.DataFrame(af[1:], columns=af[0])\n",
      "    rf = rf.rename(columns={'P>|t|':'tp', 'std err':'std_err'})\n",
      "    rf.coef = rf.coef.astype(float)\n",
      "    rf.t = rf.t.astype(float)\n",
      "    rf.std_err = rf.std_err.astype(float)\n",
      "    rf.tp = rf.tp.astype(float)\n",
      "    rf['abs_t'] = rf.t.abs()\n",
      "    return rf\n",
      "\n",
      "summary_df(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>feature</th>\n",
        "      <th>coef</th>\n",
        "      <th>std_err</th>\n",
        "      <th>t</th>\n",
        "      <th>tp</th>\n",
        "      <th>[95.0% Conf. Int.]</th>\n",
        "      <th>abs_t</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> Intercept</td>\n",
        "      <td> 18170.0000</td>\n",
        "      <td> 1003.658</td>\n",
        "      <td> 18.100</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1.62e+04  2.02e+04</td>\n",
        "      <td> 18.100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>        yr</td>\n",
        "      <td>   752.7978</td>\n",
        "      <td>  108.409</td>\n",
        "      <td>  6.944</td>\n",
        "      <td> 0</td>\n",
        "      <td>  535.051   970.544</td>\n",
        "      <td>  6.944</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 7 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "     feature        coef   std_err       t  tp  [95.0% Conf. Int.]   abs_t\n",
        "0  Intercept  18170.0000  1003.658  18.100   0  1.62e+04  2.02e+04  18.100\n",
        "1         yr    752.7978   108.409   6.944   0   535.051   970.544   6.944\n",
        "\n",
        "[2 rows x 7 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = sm.ols(formula=\"sl ~ sx + yr + rk\", data=df).fit()\n",
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>           <td>sl</td>        <th>  R-squared:         </th> <td>   0.846</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.833</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   64.64</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Sun, 09 Mar 2014</td> <th>  Prob (F-statistic):</th> <td>1.64e-18</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>14:25:25</td>     <th>  Log-Likelihood:    </th> <td> -476.26</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>    52</td>      <th>  AIC:               </th> <td>   962.5</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   972.3</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th>       <td> 1.643e+04</td> <td>  737.966</td> <td>   22.265</td> <td> 0.000</td> <td> 1.49e+04  1.79e+04</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>sx[T.male]</th>      <td> -524.1492</td> <td>  834.687</td> <td>   -0.628</td> <td> 0.533</td> <td>-2203.323  1155.024</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>rk[T.associate]</th> <td> 4373.9154</td> <td>  906.124</td> <td>    4.827</td> <td> 0.000</td> <td> 2551.030  6196.801</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>rk[T.full]</th>      <td> 9483.8419</td> <td>  912.795</td> <td>   10.390</td> <td> 0.000</td> <td> 7647.536  1.13e+04</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>yr</th>              <td>  390.9358</td> <td>   75.383</td> <td>    5.186</td> <td> 0.000</td> <td>  239.285   542.587</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>23.039</td> <th>  Durbin-Watson:     </th> <td>   1.832</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  38.727</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 1.410</td> <th>  Prob(JB):          </th> <td>3.90e-09</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 6.150</td> <th>  Cond. No.          </th> <td>    32.3</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                     sl   R-squared:                       0.846\n",
        "Model:                            OLS   Adj. R-squared:                  0.833\n",
        "Method:                 Least Squares   F-statistic:                     64.64\n",
        "Date:                Sun, 09 Mar 2014   Prob (F-statistic):           1.64e-18\n",
        "Time:                        14:25:25   Log-Likelihood:                -476.26\n",
        "No. Observations:                  52   AIC:                             962.5\n",
        "Df Residuals:                      47   BIC:                             972.3\n",
        "Df Model:                           4                                         \n",
        "===================================================================================\n",
        "                      coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "-----------------------------------------------------------------------------------\n",
        "Intercept        1.643e+04    737.966     22.265      0.000      1.49e+04  1.79e+04\n",
        "sx[T.male]       -524.1492    834.687     -0.628      0.533     -2203.323  1155.024\n",
        "rk[T.associate]  4373.9154    906.124      4.827      0.000      2551.030  6196.801\n",
        "rk[T.full]       9483.8419    912.795     10.390      0.000      7647.536  1.13e+04\n",
        "yr                390.9358     75.383      5.186      0.000       239.285   542.587\n",
        "==============================================================================\n",
        "Omnibus:                       23.039   Durbin-Watson:                   1.832\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.727\n",
        "Skew:                           1.410   Prob(JB):                     3.90e-09\n",
        "Kurtosis:                       6.150   Cond. No.                         32.3\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.groupby('rk').sl.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "rk\n",
        "assistant    18\n",
        "associate    14\n",
        "full         20\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from patsy import dmatrices\n",
      "\n",
      "y, X = dmatrices('sl ~ sx + yr + rk', data=df, return_type='dataframe')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.head"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<bound method DataFrame.head of        sl\n",
        "0   36350\n",
        "1   35350\n",
        "2   28200\n",
        "3   26775\n",
        "4   33696\n",
        "5   28516\n",
        "6   24900\n",
        "7   31909\n",
        "8   31850\n",
        "9   32850\n",
        "10  27025\n",
        "11  24750\n",
        "12  28200\n",
        "13  23712\n",
        "14  25748\n",
        "15  29342\n",
        "16  31114\n",
        "17  24742\n",
        "18  22906\n",
        "19  24450\n",
        "20  19175\n",
        "21  20525\n",
        "22  27959\n",
        "23  38045\n",
        "24  24832\n",
        "25  25400\n",
        "26  24800\n",
        "27  25500\n",
        "28  26182\n",
        "29  23725\n",
        "30  21600\n",
        "31  23300\n",
        "32  23713\n",
        "33  20690\n",
        "34  22450\n",
        "35  20850\n",
        "36  18304\n",
        "37  17095\n",
        "38  16700\n",
        "39  17600\n",
        "40  18075\n",
        "41  18000\n",
        "42  20999\n",
        "43  17250\n",
        "44  16500\n",
        "45  16094\n",
        "46  16150\n",
        "47  15350\n",
        "48  16244\n",
        "49  16686\n",
        "50  15000\n",
        "51  20300\n",
        "\n",
        "[52 rows x 1 columns]>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Intercept</th>\n",
        "      <th>sx[T.male]</th>\n",
        "      <th>rk[T.associate]</th>\n",
        "      <th>rk[T.full]</th>\n",
        "      <th>yr</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 13</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td>  7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 19</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "   Intercept  sx[T.male]  rk[T.associate]  rk[T.full]  yr\n",
        "0          1           1                0           1  25\n",
        "1          1           1                0           1  13\n",
        "2          1           1                0           1  10\n",
        "3          1           0                0           1   7\n",
        "4          1           1                0           1  19\n",
        "\n",
        "[5 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "model = LinearRegression()\n",
      "model = model.fit(X,y)\n",
      "model.score(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.8461760134902937"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'Intercept', u'sx[T.male]', u'rk[T.associate]', u'rk[T.full]', u'yr'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['pred'] = model.predict(X)\n",
      "print df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       sx    rk  yr         dg  yd     sl          pred\n",
        "0    male  full  25  doctorate  35  36350  35164.048275\n",
        "1    male  full  13  doctorate  22  35350  30472.819188\n",
        "2    male  full  10  doctorate  23  28200  29300.011916\n",
        "3  female  full   7  doctorate  27  26775  28651.353854\n",
        "4    male  full  19    masters  30  33696  32818.433731\n",
        "\n",
        "[5 rows x 7 columns]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.coef_ # Using mean absolute error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[    0.          -524.14921086  4373.91539051  9483.84186941\n",
        "    390.93575731]]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "mean_absolute_error(model.predict(X), y) # on average, about $1638 off from salary prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "1638.0060186013989"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "\n",
      "model = linear_model.Ridge(alpha = .5) # Ridge Regression (L2), alpha is the lambda / how much to regularize the numbers\n",
      "model.fit(X,y)\n",
      "# Everything is closer to 1 now\n",
      "print model.coef_ # The model's coefficients"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[    0.          -421.25668145  3779.9005536   8721.66041047\n",
        "    417.42257364]]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "\n",
      "\n",
      "model = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0]) # Ridge Regression (L2) with cross-validation and different alphas\n",
      "model.fit(X,y)\n",
      "# The higher the alpha, the higher the bias, lower the variance\n",
      "print model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[    0.          -501.05001107  4243.95176783  9319.37677802\n",
        "    396.62263309]]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "\n",
      "model = linear_model.RidgeCV(alphas=[0.1, 0.5, 0.9]) # Ridge Regression (L2) with cross-validation and different alphas\n",
      "model.fit(X,y)\n",
      "# The higher the alpha, the higher the bias, lower the variance\n",
      "print model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[    0.          -501.05001107  4243.95176783  9319.37677802\n",
        "    396.62263309]]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.alpha_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.1\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.fit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<bound method RidgeCV.fit of RidgeCV(alphas=[0.1, 0.5, 0.9], cv=None, fit_intercept=True, gcv_mode=None,\n",
        "    loss_func=None, normalize=False, score_func=None, scoring=None,\n",
        "    store_cv_values=False)>\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "train, test = train_test_split(df, test_size=0.25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['male' 'associate' 11 'doctorate' 14 24800 24581.02119399159]\n",
        " ['male' 'associate' 3 'masters' 17 23725 21453.535135486803]\n",
        " ['male' 'associate' 11 'masters' 31 23300 24581.02119399159]\n",
        " ['male' 'associate' 3 'masters' 7 26182 21453.535135486803]\n",
        " ['male' 'assistant' 16 'masters' 23 19175 22161.784590046802]\n",
        " ['female' 'assistant' 8 'doctorate' 14 18304 19558.447742397977]\n",
        " ['male' 'associate' 10 'masters' 15 22906 24190.08543667849]\n",
        " ['male' 'associate' 0 'doctorate' 7 20999 20280.727863547505]\n",
        " ['female' 'associate' 6 'masters' 29 22450 23150.491618282067]\n",
        " ['male' 'assistant' 3 'doctorate' 4 18075 17079.619744976513]\n",
        " ['female' 'full' 8 'doctorate' 24 38045 29042.289611805056]\n",
        " ['male' 'full' 13 'masters' 31 32850 30472.819187514586]\n",
        " ['male' 'full' 10 'doctorate' 23 28200 29300.01191557529]\n",
        " ['female' 'full' 7 'doctorate' 27 26775 28651.353854491957]\n",
        " ['female' 'associate' 4 'masters' 33 20690 22368.620103655867]\n",
        " ['male' 'assistant' 4 'doctorate' 4 17600 17470.55550228961]\n",
        " ['male' 'associate' 8 'masters' 31 20525 23408.213922052295]\n",
        " ['male' 'assistant' 2 'doctorate' 1 16094 16688.683987663415]\n",
        " ['female' 'assistant' 2 'doctorate' 2 15350 17212.83319851938]\n",
        " ['female' 'assistant' 3 'doctorate' 3 17250 17603.768955832482]\n",
        " ['male' 'full' 7 'doctorate' 15 29342 28127.204643635992]\n",
        " ['male' 'associate' 1 'doctorate' 9 20850 20671.663620860603]\n",
        " ['male' 'full' 16 'doctorate' 21 28516 31645.62645945388]\n",
        " ['male' 'full' 7 'doctorate' 13 27959 28127.204643635992]\n",
        " ['male' 'full' 16 'doctorate' 18 31909 31645.62645945388]\n",
        " ['male' 'assistant' 4 'doctorate' 4 17095 17470.55550228961]\n",
        " ['male' 'full' 13 'doctorate' 22 35350 30472.819187514586]\n",
        " ['male' 'assistant' 1 'doctorate' 1 16244 16297.748230350317]\n",
        " ['female' 'assistant' 1 'doctorate' 1 16686 16821.89744120628]\n",
        " ['female' 'full' 0 'masters' 32 24900 25914.803553300266]\n",
        " ['male' 'full' 19 'masters' 30 33696 32818.433731393176]\n",
        " ['male' 'full' 13 'doctorate' 20 31114 30472.819187514586]\n",
        " ['male' 'assistant' 2 'doctorate' 3 16500 16688.683987663415]\n",
        " ['male' 'full' 5 'doctorate' 18 25400 27345.333129009792]\n",
        " ['male' 'associate' 9 'masters' 27 23712 23799.149679365393]\n",
        " ['male' 'full' 9 'doctorate' 17 28200 28909.07615826219]\n",
        " ['male' 'full' 12 'doctorate' 22 27025 30081.883430201487]\n",
        " ['male' 'full' 25 'doctorate' 35 36350 35164.04827527177]\n",
        " ['male' 'full' 6 'masters' 21 24450 27736.26888632289]]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['female' 'full' 5 'doctorate' 16 25500 27869.48233986576]\n",
        " ['male' 'associate' 9 'doctorate' 12 24832 23799.149679365393]\n",
        " ['female' 'assistant' 1 'doctorate' 1 15000 16821.89744120628]\n",
        " ['male' 'assistant' 3 'masters' 11 18000 17079.619744976513]\n",
        " ['male' 'associate' 11 'masters' 14 24742 24581.02119399159]\n",
        " ['male' 'assistant' 4 'doctorate' 5 16700 17470.55550228961]\n",
        " ['male' 'associate' 15 'doctorate' 19 24750 26144.76422324399]\n",
        " ['male' 'full' 13 'masters' 30 31850 30472.819187514586]\n",
        " ['female' 'assistant' 0 'doctorate' 2 20300 16430.961683893183]\n",
        " ['female' 'assistant' 10 'masters' 15 21600 20340.319257024174]\n",
        " ['male' 'full' 9 'doctorate' 24 25748 28909.07615826219]\n",
        " ['male' 'assistant' 9 'masters' 14 23713 19425.234288855107]\n",
        " ['female' 'assistant' 2 'doctorate' 6 16150 17212.83319851938]]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "train, test = train_test_split(df, test_size=0.10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['male' 'associate' 11 'doctorate' 14 24800 24581.02119399159]\n",
        " ['male' 'assistant' 3 'doctorate' 4 18075 17079.619744976513]\n",
        " ['female' 'assistant' 8 'doctorate' 14 18304 19558.447742397977]\n",
        " ['female' 'assistant' 0 'doctorate' 2 20300 16430.961683893183]\n",
        " ['male' 'associate' 3 'masters' 17 23725 21453.535135486803]\n",
        " ['male' 'assistant' 2 'doctorate' 1 16094 16688.683987663415]\n",
        " ['male' 'assistant' 1 'doctorate' 1 16244 16297.748230350317]\n",
        " ['female' 'assistant' 10 'masters' 15 21600 20340.319257024174]\n",
        " ['male' 'full' 12 'doctorate' 22 27025 30081.883430201487]\n",
        " ['male' 'full' 13 'masters' 31 32850 30472.819187514586]\n",
        " ['male' 'associate' 1 'doctorate' 9 20850 20671.663620860603]\n",
        " ['male' 'full' 13 'doctorate' 22 35350 30472.819187514586]\n",
        " ['male' 'assistant' 3 'masters' 11 18000 17079.619744976513]\n",
        " ['male' 'full' 19 'masters' 30 33696 32818.433731393176]\n",
        " ['female' 'assistant' 2 'doctorate' 2 15350 17212.83319851938]\n",
        " ['male' 'full' 6 'masters' 21 24450 27736.26888632289]\n",
        " ['male' 'assistant' 9 'masters' 14 23713 19425.234288855107]\n",
        " ['male' 'full' 9 'doctorate' 17 28200 28909.07615826219]\n",
        " ['male' 'associate' 11 'masters' 14 24742 24581.02119399159]\n",
        " ['male' 'full' 16 'doctorate' 21 28516 31645.62645945388]\n",
        " ['male' 'full' 13 'doctorate' 20 31114 30472.819187514586]\n",
        " ['male' 'associate' 0 'doctorate' 7 20999 20280.727863547505]\n",
        " ['male' 'full' 7 'doctorate' 13 27959 28127.204643635992]\n",
        " ['female' 'associate' 6 'masters' 29 22450 23150.491618282067]\n",
        " ['male' 'full' 7 'doctorate' 15 29342 28127.204643635992]\n",
        " ['male' 'assistant' 4 'doctorate' 4 17095 17470.55550228961]\n",
        " ['male' 'full' 25 'doctorate' 35 36350 35164.04827527177]\n",
        " ['male' 'full' 16 'doctorate' 18 31909 31645.62645945388]\n",
        " ['male' 'associate' 11 'masters' 31 23300 24581.02119399159]\n",
        " ['female' 'full' 0 'masters' 32 24900 25914.803553300266]\n",
        " ['male' 'assistant' 2 'doctorate' 3 16500 16688.683987663415]\n",
        " ['male' 'assistant' 16 'masters' 23 19175 22161.784590046802]\n",
        " ['male' 'full' 13 'masters' 30 31850 30472.819187514586]\n",
        " ['male' 'assistant' 4 'doctorate' 5 16700 17470.55550228961]\n",
        " ['female' 'full' 5 'doctorate' 16 25500 27869.48233986576]\n",
        " ['male' 'associate' 9 'doctorate' 12 24832 23799.149679365393]\n",
        " ['female' 'associate' 4 'masters' 33 20690 22368.620103655867]\n",
        " ['female' 'full' 7 'doctorate' 27 26775 28651.353854491957]\n",
        " ['male' 'associate' 10 'masters' 15 22906 24190.08543667849]\n",
        " ['female' 'assistant' 3 'doctorate' 3 17250 17603.768955832482]\n",
        " ['male' 'full' 10 'doctorate' 23 28200 29300.01191557529]\n",
        " ['female' 'assistant' 2 'doctorate' 6 16150 17212.83319851938]\n",
        " ['male' 'associate' 3 'masters' 7 26182 21453.535135486803]\n",
        " ['male' 'full' 5 'doctorate' 18 25400 27345.333129009792]\n",
        " ['male' 'associate' 8 'masters' 31 20525 23408.213922052295]\n",
        " ['male' 'associate' 9 'masters' 27 23712 23799.149679365393]]\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['female' 'full' 8 'doctorate' 24 38045 29042.289611805056]\n",
        " ['female' 'assistant' 1 'doctorate' 1 15000 16821.89744120628]\n",
        " ['male' 'associate' 15 'doctorate' 19 24750 26144.76422324399]\n",
        " ['male' 'assistant' 4 'doctorate' 4 17600 17470.55550228961]\n",
        " ['male' 'full' 9 'doctorate' 24 25748 28909.07615826219]\n",
        " ['female' 'assistant' 1 'doctorate' 1 16686 16821.89744120628]]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from patsy import dmatrices\n",
      "\n",
      "X, y = dmatrices('sl ~ sx + yr + rk', data=df, return_type='dataframe')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "model = LinearRegression()\n",
      "model = model.fit(X,y)\n",
      "model.score(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "0.48606533149600384"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}